{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is this project? \u00b6 Authors \u00b6 Jordan Hartley Liam Hovell Frinze Lapuz Alex Hoffman Alex Mai Jake Yendell References \u00b6 Albert Einstein photo ref: MPI/Getty Images Diagrams by Jasper Paterson and Simon Dransfield Background art by Jordan Hartley","title":"Overview"},{"location":"#what-is-this-project","text":"","title":"What is this project?"},{"location":"#authors","text":"Jordan Hartley Liam Hovell Frinze Lapuz Alex Hoffman Alex Mai Jake Yendell","title":"Authors"},{"location":"#references","text":"Albert Einstein photo ref: MPI/Getty Images Diagrams by Jasper Paterson and Simon Dransfield Background art by Jordan Hartley","title":"References"},{"location":"administrator/","text":"Administrator Documentation \u00b6","title":"Oveview"},{"location":"administrator/#administrator-documentation","text":"","title":"Administrator Documentation"},{"location":"developer/","text":"Technical Documentation for Developer \u00b6 Application \u00b6 The website is run using a flask server. Flask is a micro framework for the backend of the website. Jinja is used inside the HTML so the display can adapt to server data as well as for running loops. Users and test attempts are saved inside a SQLite database. The username, password, and scores of the user are saved so progress can be encouraged. Development Workflow \u00b6 This project uses docker to orchestrate multiple services. Make sure to install docker, see here for documentation. Once you have it installed do the following: Environment Variables: Create the .env file \u00b6 There is a file called template.env . This contains all the configurations for the entire application for database, flask app, and pgadmin. Copy this to .env (you have to create this file). Run the Docker-Compose \u00b6 Run the following command 1 docker-compose up This one command will build all the containers. Most notably this will create the Flask Application with pip installation, and database migration to PostgreSQL. Rebuilding containers If you do need to build containers, run the following: 1 docker-compose up --build Services that are running \u00b6 There are a couple of services that are running Services URL PostgreSQL Database http://localhost:5432 PgAdmin (PostgreSQL GUI) http://localhost:8002 ReSQ Flask App http://localhost:5000 MkDocs Documentation http://localhost:8001 Going inside the container / Remote Code Execution \u00b6 Most likely you will be developing inside this container such as doing pip installation and other commands. You can do remote code execution to the container using the following command 1 docker exec -it resq_app bash This will allow you to connect to the container and do whatever command that pleases you.","title":"Overview"},{"location":"developer/#technical-documentation-for-developer","text":"","title":"Technical Documentation for Developer"},{"location":"developer/#application","text":"The website is run using a flask server. Flask is a micro framework for the backend of the website. Jinja is used inside the HTML so the display can adapt to server data as well as for running loops. Users and test attempts are saved inside a SQLite database. The username, password, and scores of the user are saved so progress can be encouraged.","title":"Application"},{"location":"developer/#development-workflow","text":"This project uses docker to orchestrate multiple services. Make sure to install docker, see here for documentation. Once you have it installed do the following:","title":"Development Workflow"},{"location":"developer/#environment-variables-create-the-env-file","text":"There is a file called template.env . This contains all the configurations for the entire application for database, flask app, and pgadmin. Copy this to .env (you have to create this file).","title":"Environment Variables: Create the .env file"},{"location":"developer/#run-the-docker-compose","text":"Run the following command 1 docker-compose up This one command will build all the containers. Most notably this will create the Flask Application with pip installation, and database migration to PostgreSQL. Rebuilding containers If you do need to build containers, run the following: 1 docker-compose up --build","title":"Run the Docker-Compose"},{"location":"developer/#services-that-are-running","text":"There are a couple of services that are running Services URL PostgreSQL Database http://localhost:5432 PgAdmin (PostgreSQL GUI) http://localhost:8002 ReSQ Flask App http://localhost:5000 MkDocs Documentation http://localhost:8001","title":"Services that are running"},{"location":"developer/#going-inside-the-container-remote-code-execution","text":"Most likely you will be developing inside this container such as doing pip installation and other commands. You can do remote code execution to the container using the following command 1 docker exec -it resq_app bash This will allow you to connect to the container and do whatever command that pleases you.","title":"Going inside the container / Remote Code Execution"},{"location":"developer/automated_testing/","text":"Automated Testing \u00b6 Unit Testing \u00b6 Unit testing is created using Pytest . Refer documentation closely to Pytest-Flask for this project. conftest conftest.py are a special file for pytest that is automatically loaded by pytest and typically contans fixtures and other setup code. Docker Container Running Make sure that you are running the docker container before doing any testing. How to run unit tests? \u00b6 Use the docker remote code execution 1 docker exec -it resq_app pytest or if you want to generate the coverage data 1 docker exec -it resq_app coverage run --source = \".\" --rcfile = .coveragerc -m pytest Coverage File This will produce a file called .coverage that contains the records and can be converted to reports. Allure Results Whenever you are running this tests, it will produce a folder called test_results that will contain results of the test. Refer below for more information about Allure. How to get coverage report? \u00b6 If you've run the tests using the above command and have .coverage file, you can generate the reports in multiple ways. More information in here . 1 coverate report -m will print the coverage report in the terminal. 1 coverage html for the html report. What is .coveragerc file? This file contains the configurations for the coverage testing. Unit Testing in Pipelines \u00b6 This was part of #12 , but was cut out of scope. Some artefacts of the code can be seen here. One particular one is the docker runtime.sh that can accomodate a APP_ENV=UNIT_TESTS to only run unit tests inside the docker. Allure Report Generator \u00b6 Allure Testing report is used as a tool to generate test report. More information here https://docs.qameta.io/allure/ This repo has a file called send_and_generate.py . It is a simple script that sends a test report to Allure and generates a report. This is currently integrated with the UWA System Health Lab Allure Setup . Documentation can be seen here . Integration Testing \u00b6 The integration tests are created with Cypress . This integration testing allows us to create frontend tests and obtain video or screenshots that can improve the quality of the test. Running Tests Via Cypress IDE \u00b6 Installment Prerequisite Install Nodejs and NPM (should be automatically installed with Nodejs). Go to integration_tests folder and do npm install . That is going to install your package.json packages. In one terminal, run docker-compose up for running application. Without closing terminal opened in 1), open a new terminal and go to /integration_tests and: Run yarn run cypress:open or Run npm run cypress:open Note that by using this, the Cypress IDE will be running outside the docker container. Configuring Cypress \u00b6 Cypress configuration can be adjusted in the cypress.json file. If you want to define global varibles, this is the place to do it. Global variables can be used in the code with Cypress.env('VAR') . More information can be seen in the official docs https://docs.cypress.io/guides/references/configuration Writing Tests \u00b6 There are 2 ways to create tests: By writing code tests, see Writing Test Or by using the Cypress Studio Cypress studio makes it easy to create test by recording the user action through the Cypress IDE. Upon action of the user, Cypress studio writes codes in the tests which could be adjusted later for flexibility. To use Cypress Studio Test Creation Firstly, you need a test suite ends with .spec.js in the integration_tests/cypress/integration folder (either newly created from a test template or existing test). Test Template 1 2 3 4 5 6 7 8 9 describe ( 'Test Suite' , () => { beforeEach (() => { // Setup Scripts Here }) it ( 'Test Name' , () => { // Extend test with Cypress Studio }) }) Select a test suite in the Cypress IDE to extend Hover on the test, and click the \"magic wand\" icon near the test Interact with the Cypress Web interface as if you are the test runner Save the test when you are done Modify the tests created by Cypress IDE as you need Magic Wand Icon Test files and directory organization \u00b6 All test specs are located in integration_tests/cypress/integration . We recomend follow an structure by feature. In integration_tests/cypress/support you can write reusable pieces of code for execute in all your tests with commands . Test Results \u00b6 Results after tests suite finished are stored in the following folders: integration_tests/cypress/screenshots : Screenshots generated by cypress integration_tests/cypress/videos : Videos generated by cypress integration_tests/cypress/results : Allure formatted results Allure Integration with Cypress \u00b6 Cypress test runner has installed an allure plugin which is used to generate tests results with allure format. Documentation","title":"Automated Testing"},{"location":"developer/automated_testing/#automated-testing","text":"","title":"Automated Testing"},{"location":"developer/automated_testing/#unit-testing","text":"Unit testing is created using Pytest . Refer documentation closely to Pytest-Flask for this project. conftest conftest.py are a special file for pytest that is automatically loaded by pytest and typically contans fixtures and other setup code. Docker Container Running Make sure that you are running the docker container before doing any testing.","title":"Unit Testing"},{"location":"developer/automated_testing/#how-to-run-unit-tests","text":"Use the docker remote code execution 1 docker exec -it resq_app pytest or if you want to generate the coverage data 1 docker exec -it resq_app coverage run --source = \".\" --rcfile = .coveragerc -m pytest Coverage File This will produce a file called .coverage that contains the records and can be converted to reports. Allure Results Whenever you are running this tests, it will produce a folder called test_results that will contain results of the test. Refer below for more information about Allure.","title":"How to run unit tests?"},{"location":"developer/automated_testing/#how-to-get-coverage-report","text":"If you've run the tests using the above command and have .coverage file, you can generate the reports in multiple ways. More information in here . 1 coverate report -m will print the coverage report in the terminal. 1 coverage html for the html report. What is .coveragerc file? This file contains the configurations for the coverage testing.","title":"How to get coverage report?"},{"location":"developer/automated_testing/#unit-testing-in-pipelines","text":"This was part of #12 , but was cut out of scope. Some artefacts of the code can be seen here. One particular one is the docker runtime.sh that can accomodate a APP_ENV=UNIT_TESTS to only run unit tests inside the docker.","title":"Unit Testing in Pipelines"},{"location":"developer/automated_testing/#allure-report-generator","text":"Allure Testing report is used as a tool to generate test report. More information here https://docs.qameta.io/allure/ This repo has a file called send_and_generate.py . It is a simple script that sends a test report to Allure and generates a report. This is currently integrated with the UWA System Health Lab Allure Setup . Documentation can be seen here .","title":"Allure Report Generator"},{"location":"developer/automated_testing/#integration-testing","text":"The integration tests are created with Cypress . This integration testing allows us to create frontend tests and obtain video or screenshots that can improve the quality of the test.","title":"Integration Testing"},{"location":"developer/automated_testing/#running-tests-via-cypress-ide","text":"Installment Prerequisite Install Nodejs and NPM (should be automatically installed with Nodejs). Go to integration_tests folder and do npm install . That is going to install your package.json packages. In one terminal, run docker-compose up for running application. Without closing terminal opened in 1), open a new terminal and go to /integration_tests and: Run yarn run cypress:open or Run npm run cypress:open Note that by using this, the Cypress IDE will be running outside the docker container.","title":"Running Tests Via Cypress IDE"},{"location":"developer/automated_testing/#configuring-cypress","text":"Cypress configuration can be adjusted in the cypress.json file. If you want to define global varibles, this is the place to do it. Global variables can be used in the code with Cypress.env('VAR') . More information can be seen in the official docs https://docs.cypress.io/guides/references/configuration","title":"Configuring Cypress"},{"location":"developer/automated_testing/#writing-tests","text":"There are 2 ways to create tests: By writing code tests, see Writing Test Or by using the Cypress Studio Cypress studio makes it easy to create test by recording the user action through the Cypress IDE. Upon action of the user, Cypress studio writes codes in the tests which could be adjusted later for flexibility. To use Cypress Studio Test Creation Firstly, you need a test suite ends with .spec.js in the integration_tests/cypress/integration folder (either newly created from a test template or existing test). Test Template 1 2 3 4 5 6 7 8 9 describe ( 'Test Suite' , () => { beforeEach (() => { // Setup Scripts Here }) it ( 'Test Name' , () => { // Extend test with Cypress Studio }) }) Select a test suite in the Cypress IDE to extend Hover on the test, and click the \"magic wand\" icon near the test Interact with the Cypress Web interface as if you are the test runner Save the test when you are done Modify the tests created by Cypress IDE as you need Magic Wand Icon","title":"Writing Tests"},{"location":"developer/automated_testing/#test-files-and-directory-organization","text":"All test specs are located in integration_tests/cypress/integration . We recomend follow an structure by feature. In integration_tests/cypress/support you can write reusable pieces of code for execute in all your tests with commands .","title":"Test files and directory organization"},{"location":"developer/automated_testing/#test-results","text":"Results after tests suite finished are stored in the following folders: integration_tests/cypress/screenshots : Screenshots generated by cypress integration_tests/cypress/videos : Videos generated by cypress integration_tests/cypress/results : Allure formatted results","title":"Test Results"},{"location":"developer/automated_testing/#allure-integration-with-cypress","text":"Cypress test runner has installed an allure plugin which is used to generate tests results with allure format. Documentation","title":"Allure Integration with Cypress"},{"location":"developer/ci_pipeline/","text":"Continous Integration Pipeline \u00b6 These are just scripts that run whenever you do pull requests and successful merges. There are a couple of scripts that are currently configured see .github/workflows : Automated Documentation Deployment docs.yml \u00b6 This automatically deploys this documentation whenever main is updated with new changes.","title":"CI Pipeline"},{"location":"developer/ci_pipeline/#continous-integration-pipeline","text":"These are just scripts that run whenever you do pull requests and successful merges. There are a couple of scripts that are currently configured see .github/workflows :","title":"Continous Integration Pipeline"},{"location":"developer/ci_pipeline/#automated-documentation-deployment-docsyml","text":"This automatically deploys this documentation whenever main is updated with new changes.","title":"Automated Documentation Deployment docs.yml"},{"location":"developer/coding_patterns/","text":"Coding Patterns \u00b6 Casing \u00b6 This codebase will be using camel casing. Linters / Formatters \u00b6 This will automatically format your code if you install ESLint in VS Code or type yarn lint in the specific folders. Make sure you have installed the devDependencies so additional linters can be used. Github Issues and Pull Requests \u00b6 Most changes in the codebase can be matched to a github issue that contains description of the work that needs to be done. Each of the pull request are matched to this github issue with the branch name that has a standard c{Issue Number}-{branch name} . The issue number allows referencing especially when resolving reason for change. Development with Docker \u00b6 The development is done with Docker to orchestrate multiple services as defined in the docker-compose.yml file: Documentation at localhost:8001 Inconsistencies \u00b6 During the project, different developers have different terminology. Some of the inconsistencies are documented below queue means Team Name as well \u00b6 queue refers to where the student belongs to in the queue. This can either be StudySmarter or Librarian team.","title":"Coding Patterns"},{"location":"developer/coding_patterns/#coding-patterns","text":"","title":"Coding Patterns"},{"location":"developer/coding_patterns/#casing","text":"This codebase will be using camel casing.","title":"Casing"},{"location":"developer/coding_patterns/#linters-formatters","text":"This will automatically format your code if you install ESLint in VS Code or type yarn lint in the specific folders. Make sure you have installed the devDependencies so additional linters can be used.","title":"Linters / Formatters"},{"location":"developer/coding_patterns/#github-issues-and-pull-requests","text":"Most changes in the codebase can be matched to a github issue that contains description of the work that needs to be done. Each of the pull request are matched to this github issue with the branch name that has a standard c{Issue Number}-{branch name} . The issue number allows referencing especially when resolving reason for change.","title":"Github Issues and Pull Requests"},{"location":"developer/coding_patterns/#development-with-docker","text":"The development is done with Docker to orchestrate multiple services as defined in the docker-compose.yml file: Documentation at localhost:8001","title":"Development with Docker"},{"location":"developer/coding_patterns/#inconsistencies","text":"During the project, different developers have different terminology. Some of the inconsistencies are documented below","title":"Inconsistencies"},{"location":"developer/coding_patterns/#queue-means-team-name-as-well","text":"queue refers to where the student belongs to in the queue. This can either be StudySmarter or Librarian team.","title":"queue means Team Name as well"},{"location":"developer/deployment/","text":"Deployment \u00b6 The deployment of ReSQ is in the UWA Infrastructure (to be precise in the UWA System Health Lab ). The reason being is that permission is granted to Frinze Erin Lapuz (Software Team Lead of the Redbacks Team at the UWA System Health Lab). There a couple of steps that were involved in doing this: DNS Configuration \u00b6 This is a 1 time configuration The domain name is set to \"resq.systemhealthlab.com\" in UWA Cloudflare. NGINX Configuration \u00b6 Using Binchicken , I have created the NGINX configuration that will handle all requests going to the application (reverse-proxy). Nginx Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 server { server_name resq.systemhealthlab.com ; location / { proxy_set_header Host $host ; proxy_set_header X-Real-IP $remote_addr ; proxy_pass http://localhost:10023 ; proxy_set_header X-Forwarded-Proto $scheme ; proxy_http_version 1 .1 ; proxy_set_header Upgrade $http_upgrade ; proxy_set_header Connection \"upgrade\" ; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for ; proxy_read_timeout 3m ; proxy_send_timeout 3m ; } listen [::]:443 ssl ; listen 443 ssl ; ssl_certificate /etc/letsencrypt/live/systemhealthlab.com/fullchain.pem ; ssl_certificate_key /etc/letsencrypt/live/systemhealthlab.com/privkey.pem ; include /etc/letsencrypt/options-ssl-nginx.conf ; ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem ; } server { listen 80 ; listen [::]:80 ; server_name resq.systemhealthlab.com www.resq.systemhealthlab.com ; return 301 https://resq.systemhealthlab.com $request_uri ; } Diagrammatic Explanation \u00b6 graph TD User -->|User goes to resq.systemhealthlab.com|Cloudflare Cloudflare-->|Sees that it is under the DNS registed on VPS|VPS subgraph UWA Infrastructure VPS -->|Configuration on Locations|NGINX NGINX -->|Host Port Location| VPS VPS --> ReSQ subgraph Docker ReSQ Other_UWA_SHL_Services end end Deployment with Docker Image \u00b6 This requires access towards the application inside the VPS. The easiest way to do this is to have access with the VPS through SSH (you may need permission for this). Once you are in there, do 1 git pull to pull in the new changes from the main branch. git pull This assumes that you already have the repository in the VPS. If it does not exist, just do git clone . Then run 1 sh deploy.sh This will rebuild all the containers (for production) as well as the new code. Gunicorn Process in Production \u00b6 The reason as to why we gunicorn process instead of flask run in production is for the main following reason: gunicorn allows parallelising of HTTP request automatic disconnect towards the database after the short-lived process (of responding to HTTP request) More information about its setup here .","title":"Deployment"},{"location":"developer/deployment/#deployment","text":"The deployment of ReSQ is in the UWA Infrastructure (to be precise in the UWA System Health Lab ). The reason being is that permission is granted to Frinze Erin Lapuz (Software Team Lead of the Redbacks Team at the UWA System Health Lab). There a couple of steps that were involved in doing this:","title":"Deployment"},{"location":"developer/deployment/#dns-configuration","text":"This is a 1 time configuration The domain name is set to \"resq.systemhealthlab.com\" in UWA Cloudflare.","title":"DNS Configuration"},{"location":"developer/deployment/#nginx-configuration","text":"Using Binchicken , I have created the NGINX configuration that will handle all requests going to the application (reverse-proxy). Nginx Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 server { server_name resq.systemhealthlab.com ; location / { proxy_set_header Host $host ; proxy_set_header X-Real-IP $remote_addr ; proxy_pass http://localhost:10023 ; proxy_set_header X-Forwarded-Proto $scheme ; proxy_http_version 1 .1 ; proxy_set_header Upgrade $http_upgrade ; proxy_set_header Connection \"upgrade\" ; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for ; proxy_read_timeout 3m ; proxy_send_timeout 3m ; } listen [::]:443 ssl ; listen 443 ssl ; ssl_certificate /etc/letsencrypt/live/systemhealthlab.com/fullchain.pem ; ssl_certificate_key /etc/letsencrypt/live/systemhealthlab.com/privkey.pem ; include /etc/letsencrypt/options-ssl-nginx.conf ; ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem ; } server { listen 80 ; listen [::]:80 ; server_name resq.systemhealthlab.com www.resq.systemhealthlab.com ; return 301 https://resq.systemhealthlab.com $request_uri ; }","title":"NGINX Configuration"},{"location":"developer/deployment/#diagrammatic-explanation","text":"graph TD User -->|User goes to resq.systemhealthlab.com|Cloudflare Cloudflare-->|Sees that it is under the DNS registed on VPS|VPS subgraph UWA Infrastructure VPS -->|Configuration on Locations|NGINX NGINX -->|Host Port Location| VPS VPS --> ReSQ subgraph Docker ReSQ Other_UWA_SHL_Services end end","title":"Diagrammatic Explanation"},{"location":"developer/deployment/#deployment-with-docker-image","text":"This requires access towards the application inside the VPS. The easiest way to do this is to have access with the VPS through SSH (you may need permission for this). Once you are in there, do 1 git pull to pull in the new changes from the main branch. git pull This assumes that you already have the repository in the VPS. If it does not exist, just do git clone . Then run 1 sh deploy.sh This will rebuild all the containers (for production) as well as the new code.","title":"Deployment with Docker Image"},{"location":"developer/deployment/#gunicorn-process-in-production","text":"The reason as to why we gunicorn process instead of flask run in production is for the main following reason: gunicorn allows parallelising of HTTP request automatic disconnect towards the database after the short-lived process (of responding to HTTP request) More information about its setup here .","title":"Gunicorn Process in Production"},{"location":"developer/requirements/","text":"Requirements \u00b6 Acronyms, Abbreviations and Definitions \u00b6 UWA: The University of Western Australia Aim and Scope \u00b6 Requirements \u00b6 Stage 1 Functional Requirements \u00b6 The following are the core functional requirements for the first stage application Users \u00b6 Stage 2 Functional Requirements \u00b6 \"Nice to have\" \u00b6 Some of the \"nice to haves\" of this project will be covered in this requirements documents. Howevever, \"nice to haves\" usually will come along as the users of the system see fit. This will be documented in the Issue Tracking Management sytem of the code repository. Non-functional Requirements \u00b6 Identifier Name Description NFR1 Security Only authenticated and authorised users should be able to perform actions such as adding equipment, updating equipment location and information, or searching for specific equipment. NFR2 Performance The loading time should not hinder the user experience and productivity of the user in the website. The page/actions should have a loading time < 5 seconds on most computing environments on standard internet connections** NFR3 Maintainable and extensible The website should be relatively easy to update and extended to accomodate for new contexts. NFR4 Recoverable In the event of the web server or database server crashing, all stored data should be fully recoverable. NFR5 Intuitive user interface The website should have an intuitive / easy-to-use user interface, so that users will be able to easily use the website and update the equipment database NFR6 Compatibility The application should be compatible with recent versions of the major browsers (Safari, Chrome, Firefox and Edge) on laptop and desktop computers NFR7 Deployability The application should be compatible with deployment in the SHL VPS Proposed Solution \u00b6 The proposed solution is to build a custom web application that will encompass and satisfy the requirements (by completing the suggested \"ideal solution\" as per the Aim and Scope ). Some research for existing design solution has been done for this project see Appendix: Existing Design Solution . The beauty of custom web application for the team is that it upskills the current software engineers as aligned in the purpose of this unit, and the high possibility of extending application depending on the requirements without being constrained with the bulk of codebase of other unmaintained opensource projects. Comparatively to enterprise systems, most enterprise systems will charge per users that use the system, this easily becomes expensive because the amount of users that will use the system should be able to accomodate the number of users that are interested in looking for the assets. Core Technologies \u00b6 The custom web application will aim to satisfy all the requirements in here along with the \"Nice to haves\" as they come up. The application will be built using the ... The authentication system will be outsourced to the UWA Pheme Authentication API to allow any users in with a UWA Pheme account to login. Docker \u00b6 Docker is a deployment technology that allows virtualization in a server to allow the packaging of software into containers for deployment. To satisfy NFR7 - Deployability, the web platform will use docker to allow the deployment through the SHL VPS Server. Furthermore, Docker will be used for orchestration of different services in development to increase speed of development, and reduce inconsistency between developers devices (NFR3 - Maintainable and extensible). Code Quality \u00b6 The code quality will be ensured by peer reviews between the developers in the team. Code Storage and Development Control \u00b6 Git source control will be used, using the remote UWA System Health Lab organisational GitHub (NFR3 - Maintenace and Extensibility). Prototype \u00b6 See the Prototype mentioned in Figma Interface Prototype Execution Team \u00b6 The development of the web platform will be performed by Development and Methodology \u00b6 As per the staged requirement, majority of the development will take place on the stage 1 whereas stage 2 are feature-based requirements for the syste,. Appendix \u00b6 Existing Design Solutions \u00b6 Some of the design solutions that have been considered with great detail and justification are here.","title":"Requirements"},{"location":"developer/requirements/#requirements","text":"","title":"Requirements"},{"location":"developer/requirements/#acronyms-abbreviations-and-definitions","text":"UWA: The University of Western Australia","title":"Acronyms, Abbreviations and Definitions"},{"location":"developer/requirements/#aim-and-scope","text":"","title":"Aim and Scope"},{"location":"developer/requirements/#requirements_1","text":"","title":"Requirements"},{"location":"developer/requirements/#stage-1-functional-requirements","text":"The following are the core functional requirements for the first stage application","title":"Stage 1 Functional Requirements"},{"location":"developer/requirements/#users","text":"","title":"Users"},{"location":"developer/requirements/#stage-2-functional-requirements","text":"","title":"Stage 2 Functional Requirements"},{"location":"developer/requirements/#nice-to-have","text":"Some of the \"nice to haves\" of this project will be covered in this requirements documents. Howevever, \"nice to haves\" usually will come along as the users of the system see fit. This will be documented in the Issue Tracking Management sytem of the code repository.","title":"\"Nice to have\""},{"location":"developer/requirements/#non-functional-requirements","text":"Identifier Name Description NFR1 Security Only authenticated and authorised users should be able to perform actions such as adding equipment, updating equipment location and information, or searching for specific equipment. NFR2 Performance The loading time should not hinder the user experience and productivity of the user in the website. The page/actions should have a loading time < 5 seconds on most computing environments on standard internet connections** NFR3 Maintainable and extensible The website should be relatively easy to update and extended to accomodate for new contexts. NFR4 Recoverable In the event of the web server or database server crashing, all stored data should be fully recoverable. NFR5 Intuitive user interface The website should have an intuitive / easy-to-use user interface, so that users will be able to easily use the website and update the equipment database NFR6 Compatibility The application should be compatible with recent versions of the major browsers (Safari, Chrome, Firefox and Edge) on laptop and desktop computers NFR7 Deployability The application should be compatible with deployment in the SHL VPS","title":"Non-functional Requirements"},{"location":"developer/requirements/#proposed-solution","text":"The proposed solution is to build a custom web application that will encompass and satisfy the requirements (by completing the suggested \"ideal solution\" as per the Aim and Scope ). Some research for existing design solution has been done for this project see Appendix: Existing Design Solution . The beauty of custom web application for the team is that it upskills the current software engineers as aligned in the purpose of this unit, and the high possibility of extending application depending on the requirements without being constrained with the bulk of codebase of other unmaintained opensource projects. Comparatively to enterprise systems, most enterprise systems will charge per users that use the system, this easily becomes expensive because the amount of users that will use the system should be able to accomodate the number of users that are interested in looking for the assets.","title":"Proposed Solution"},{"location":"developer/requirements/#core-technologies","text":"The custom web application will aim to satisfy all the requirements in here along with the \"Nice to haves\" as they come up. The application will be built using the ... The authentication system will be outsourced to the UWA Pheme Authentication API to allow any users in with a UWA Pheme account to login.","title":"Core Technologies"},{"location":"developer/requirements/#docker","text":"Docker is a deployment technology that allows virtualization in a server to allow the packaging of software into containers for deployment. To satisfy NFR7 - Deployability, the web platform will use docker to allow the deployment through the SHL VPS Server. Furthermore, Docker will be used for orchestration of different services in development to increase speed of development, and reduce inconsistency between developers devices (NFR3 - Maintainable and extensible).","title":"Docker"},{"location":"developer/requirements/#code-quality","text":"The code quality will be ensured by peer reviews between the developers in the team.","title":"Code Quality"},{"location":"developer/requirements/#code-storage-and-development-control","text":"Git source control will be used, using the remote UWA System Health Lab organisational GitHub (NFR3 - Maintenace and Extensibility).","title":"Code Storage and Development Control"},{"location":"developer/requirements/#prototype","text":"See the Prototype mentioned in Figma Interface Prototype","title":"Prototype"},{"location":"developer/requirements/#execution-team","text":"The development of the web platform will be performed by","title":"Execution Team"},{"location":"developer/requirements/#development-and-methodology","text":"As per the staged requirement, majority of the development will take place on the stage 1 whereas stage 2 are feature-based requirements for the syste,.","title":"Development and Methodology"},{"location":"developer/requirements/#appendix","text":"","title":"Appendix"},{"location":"developer/requirements/#existing-design-solutions","text":"Some of the design solutions that have been considered with great detail and justification are here.","title":"Existing Design Solutions"},{"location":"developer/backend/","text":"Backend \u00b6","title":"Overview"},{"location":"developer/backend/#backend","text":"","title":"Backend"},{"location":"developer/backend/testing/","text":"Testing \u00b6 TODO","title":"Testing"},{"location":"developer/backend/testing/#testing","text":"TODO","title":"Testing"},{"location":"developer/frontend/","text":"Frontend \u00b6","title":"Overview"},{"location":"developer/frontend/#frontend","text":"","title":"Frontend"},{"location":"user/","text":"User Documentation \u00b6 How to access the website \u00b6 Click here to redirect to the website. User will need username and password to login. There will be 3 main tabs in the website, which are Queue, Data Analytics and Export Data Queue \u00b6 User can manage student sessions in the Queue tab. There are 3 tables, 2 of which are STUDYSmarter queue and Librarian queue. Students will be put into either queue depending on user's choice. Staff management \u00b6 On the right side of the queue home page, you can see 2 small boxes saying \"STUDYSmarter Team Available\" and \"Librarians Available\". You can click the \"+\" and \"-\" icon to modify the number base on your current available staff. If you try to add student to the inSession queue which exceeds your current setup for each staff type, the website will give a warning alert and require you to modify the staff number. Add to queue \u00b6 In order to add a student to a waiting queue, look for the \"ADD TO QUEUE\" button in the top right corner A form will show up as below. In this form, you can enter student information and choose the queue type between \"STUDYSmarter\" and \"Librarian\" When successfully added, the student information will show up in the corresponding queue. Below is an example Managing a session \u00b6 If you want to move students from either waiting queue to \"Current Session\" table, click the green button in the \"Actions\" column If a student cancel the appointment, you can remove her/him from the waiting queue by clicking the red button in the \"Actions\" column A message box will show up and ask to confirm your action, click \"Yes\". Finish/Undo a session \u00b6 When a session is done, user can click the green button to finish the session. When user accidentally added a student to this table from waiting queue, undo it by choosing the undo button Data analytics \u00b6 This website provide some basic data analytics for \"at a glance\" view. There will be 3 charts generated in the Data analytics tab: Students visited per day in the chosen week The percentages of popular units in that week Comparison between students enter STUDYSmarter and Librarian queue in that week In order to generate data analytics for a chosen week: Choose an arbitrary day in the week you want to generate data Click submit Export data \u00b6 If user wants to export data to a csv file for further data analysis: Step 1: Navigate to the 'Export Data' tab Step 2: There are premade options such as \"Last week\" or \"Last Day\". You can also choose \"Custom\" option to export data between a period of your choice - Step 3: Click 'Submit', then download the file","title":"Overview"},{"location":"user/#user-documentation","text":"","title":"User Documentation"},{"location":"user/#how-to-access-the-website","text":"Click here to redirect to the website. User will need username and password to login. There will be 3 main tabs in the website, which are Queue, Data Analytics and Export Data","title":"How to access the website"},{"location":"user/#queue","text":"User can manage student sessions in the Queue tab. There are 3 tables, 2 of which are STUDYSmarter queue and Librarian queue. Students will be put into either queue depending on user's choice.","title":"Queue"},{"location":"user/#staff-management","text":"On the right side of the queue home page, you can see 2 small boxes saying \"STUDYSmarter Team Available\" and \"Librarians Available\". You can click the \"+\" and \"-\" icon to modify the number base on your current available staff. If you try to add student to the inSession queue which exceeds your current setup for each staff type, the website will give a warning alert and require you to modify the staff number.","title":"Staff management"},{"location":"user/#add-to-queue","text":"In order to add a student to a waiting queue, look for the \"ADD TO QUEUE\" button in the top right corner A form will show up as below. In this form, you can enter student information and choose the queue type between \"STUDYSmarter\" and \"Librarian\" When successfully added, the student information will show up in the corresponding queue. Below is an example","title":"Add to queue"},{"location":"user/#managing-a-session","text":"If you want to move students from either waiting queue to \"Current Session\" table, click the green button in the \"Actions\" column If a student cancel the appointment, you can remove her/him from the waiting queue by clicking the red button in the \"Actions\" column A message box will show up and ask to confirm your action, click \"Yes\".","title":"Managing a session"},{"location":"user/#finishundo-a-session","text":"When a session is done, user can click the green button to finish the session. When user accidentally added a student to this table from waiting queue, undo it by choosing the undo button","title":"Finish/Undo a session"},{"location":"user/#data-analytics","text":"This website provide some basic data analytics for \"at a glance\" view. There will be 3 charts generated in the Data analytics tab: Students visited per day in the chosen week The percentages of popular units in that week Comparison between students enter STUDYSmarter and Librarian queue in that week In order to generate data analytics for a chosen week: Choose an arbitrary day in the week you want to generate data Click submit","title":"Data analytics"},{"location":"user/#export-data","text":"If user wants to export data to a csv file for further data analysis: Step 1: Navigate to the 'Export Data' tab Step 2: There are premade options such as \"Last week\" or \"Last Day\". You can also choose \"Custom\" option to export data between a period of your choice - Step 3: Click 'Submit', then download the file","title":"Export data"}]}